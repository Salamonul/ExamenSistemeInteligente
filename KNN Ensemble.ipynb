{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Solving the Problem of the K Parameter in the KNN\n",
    "# Classifier Using an Ensemble Learning Approach\"\n",
    "\n",
    "# Ideea principala a acestui articol este utilizarea algoritmului # KNN fara a specifica parametrul k in mod empiric.\n",
    "\n",
    "\n",
    "# Metoda propusa in acest articol a fost asamblarea clasificatoarelor KNN cu k=1, 3, 5, 7 ... n (unde n reprezinta radacina patrata a dimensiunii setului de date) intr-un singur clasificator care va clasifica in urma deciziei majoritare \n",
    "\n",
    "# Pasul 1: importam librariile necesare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pasul 2: definim metoda de instantiere a clasificatorului asamblat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting(n):\n",
    "\tk=-1; count=0; models = list(); label=\"-NN\"; labelList=[];\n",
    "\twhile k<n: \n",
    "\t\tk=k+2;\n",
    "\t\tcount=count+1;\n",
    "\t\tlabelList.append(str(k)+label)\n",
    "\t\t# define the base models\n",
    "\t\tmodels.append((str(k)+label, KNeighborsClassifier(n_neighbors=k)))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pasul 3: vom crea o lista cu clasificatorii care vor fi evaluati, aceasta lista contine clasificatorii 1NN, 3NN, 5NN.... nNN (unde n reprezinta radacina patrata a dimensiunii setului de date), si clasificatorul care asambleaza toti clasificatorii mentionati anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models(n):\n",
    "\tmodels = dict()\n",
    "\tk=-1; count=0; label=\"-NN\"; labelList=[];\n",
    "\twhile k<n: \n",
    "\t\tk=k+2;\n",
    "\t\tcount=count+1;\n",
    "\t\tlabelList.append(str(k)+label)\n",
    "\t\t# define the base models\n",
    "\t\tif(k<10):\n",
    "\t\t\tmodels[' '+str(k)+label] = KNeighborsClassifier(n_neighbors=k)\n",
    "\t\telse:\n",
    "\t\t\tmodels[str(k)+label] = KNeighborsClassifier(n_neighbors=k)\n",
    "\t\t\n",
    "\tmodels['ensemble'] = get_voting(n)\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasul 4: vom crea o metoda care va evalua fiecare model individual, metrica de interes fiind acuratetea. Pentru testare am impartit setul de date in 70% date de antrenare si 30% date de testare cum a specificat autorul documentului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=25, n_repeats=1, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemplu propus de autor foloseste setul de date QSAR.csv care contine 43 de feature-uri, din care primele 42 sunt date de intrare, iar al 43-lea feature reprezinta clasa din care face parte obiectul interogat. \n",
    "# Dimensiunea setului de date este de 1055 de unde tragem concluzia ca vom utiliza clasificatorii 1NN, 3NN, 5NN, 7NN, 9NN, 11NN, 13NN, 15NN, 17NN, 19NN, 21NN, 23NN, 25NN, 27NN, 29NN, 31NN(deoarece 31 este cel mai apropiat numar impar de radical(1055)) in cadrul clasificatorului asamblat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"QSAR .csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F43')], data['F43']\n",
    "\n",
    "n=int(math.sqrt(1055))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datorita unui bug modelele sunt analizate intr-o ordine aleatoare, motiv pentru care voi introduce o sortare alfabetica a numelor clasificatoriilor care va ordona indirect si lista performantelor obtinute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1-NN 0.8029 \n",
      " 3-NN 0.8276 \n",
      " 5-NN 0.8199 \n",
      " 7-NN 0.8256 \n",
      " 9-NN 0.8226 \n",
      "11-NN 0.8066 \n",
      "13-NN 0.8095 \n",
      "15-NN 0.8113 \n",
      "17-NN 0.8018 \n",
      "19-NN 0.7923 \n",
      "21-NN 0.7876 \n",
      "23-NN 0.7839 \n",
      "25-NN 0.7811 \n",
      "27-NN 0.7716 \n",
      "29-NN 0.7716 \n",
      "31-NN 0.7726 \n",
      "ensemble 0.8085 \n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results (unsorted)\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1-NN 0.8029 \n",
      " 3-NN 0.8276 \n",
      " 5-NN 0.8199 \n",
      " 7-NN 0.8256 \n",
      " 9-NN 0.8226 \n",
      "11-NN 0.8066 \n",
      "13-NN 0.8095 \n",
      "15-NN 0.8113 \n",
      "17-NN 0.8018 \n",
      "19-NN 0.7923 \n",
      "21-NN 0.7876 \n",
      "23-NN 0.7839 \n",
      "25-NN 0.7811 \n",
      "27-NN 0.7716 \n",
      "29-NN 0.7716 \n",
      "31-NN 0.7726 \n",
      "ensemble 0.8085 \n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results (sorted)\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
