{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Solving the Problem of the K Parameter in the KNN Classifier Using an Ensemble Learning Approach\"\n",
    "\n",
    "# Ideea principala a acestui articol este utilizarea algoritmului KNN fara a specifica parametrul k in mod empiric.\n",
    "\n",
    "\n",
    "# Metoda propusa in acest articol a fost asamblarea clasificatoarelor KNN cu k=1, 3, 5, 7 ... n (unde n reprezinta radacina patrata a dimensiunii setului de date) intr-un singur clasificator care va clasifica in urma deciziei majoritare \n",
    "\n",
    "# Pasul 1: importam librariile necesare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pasul 2: definim metoda de instantiere a clasificatorului asamblat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a voting ensemble of models\n",
    "def get_voting(n):\n",
    "\tk=-1; count=0; models = list(); label=\"-NN\"; labelList=[];\n",
    "\twhile k<n: \n",
    "\t\tk=k+2;\n",
    "\t\tcount=count+1;\n",
    "\t\tlabelList.append(str(k)+label)\n",
    "\t\t# define the base models\n",
    "\t\tmodels.append((str(k)+label, KNeighborsClassifier(n_neighbors=k)))\n",
    "\t# define the voting ensemble\n",
    "\tensemble = VotingClassifier(estimators=models, voting='hard')\n",
    "\treturn ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pasul 3: vom crea o lista cu clasificatorii care vor fi evaluati, aceasta lista contine clasificatorii 1NN, 3NN, 5NN.... nNN (unde n reprezinta radacina patrata a dimensiunii setului de date), si clasificatorul care asambleaza toti clasificatorii mentionati anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models(n):\n",
    "\tmodels = dict()\n",
    "\tk=-1; count=0; label=\"-NN\"; labelList=[];\n",
    "\twhile k<n: \n",
    "\t\tk=k+2;\n",
    "\t\tcount=count+1;\n",
    "\t\tlabelList.append(str(k)+label)\n",
    "\t\t# define the base models\n",
    "\t\tif(k<10):\n",
    "\t\t\tmodels['  '+str(k)+label] = KNeighborsClassifier(n_neighbors=k)\n",
    "\t\telif(k>10 and k<100):\n",
    "\t\t\tmodels[' '+str(k)+label] = KNeighborsClassifier(n_neighbors=k)\n",
    "\t\telse:\n",
    "\t\t\tmodels[str(k)+label] = KNeighborsClassifier(n_neighbors=k)\n",
    "\t\t\n",
    "\tmodels['ensemble'] = get_voting(n)\n",
    "\treturn models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasul 4: vom crea o metoda care va evalua fiecare model individual, metrica de interes fiind acuratetea. Pentru testare am impartit setul de date in 70% date de antrenare si 30% date de testare cum a specificat autorul documentului"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemplu propus de autor foloseste setul de date QSAR.csv care contine 43 de feature-uri, din care primele 42 sunt date de intrare, iar al 43-lea feature reprezinta clasa din care face parte obiectul interogat. \n",
    "# Dimensiunea setului de date este de 1055 de unde tragem concluzia ca vom utiliza clasificatorii 1NN, 3NN, 5NN, 7NN, 9NN, 11NN, 13NN, 15NN, 17NN, 19NN, 21NN, 23NN, 25NN, 27NN, 29NN, 31NN(deoarece 31 este cel mai apropiat numar impar de radical(1055)) in cadrul clasificatorului asamblat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"QSAR .csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F43')], data['F43']\n",
    "\n",
    "n=int(math.sqrt(1055))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datorita unui bug modelele sunt analizate intr-o ordine aleatoare, motiv pentru care voi introduce o sortare alfabetica a numelor clasificatoriilor care va ordona indirect si lista performantelor obtinute\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1-NN 0.8029 \n",
      "  3-NN 0.8276 \n",
      "  5-NN 0.8199 \n",
      "  7-NN 0.8256 \n",
      "  9-NN 0.8226 \n",
      " 11-NN 0.8066 \n",
      " 13-NN 0.8095 \n",
      " 15-NN 0.8113 \n",
      " 17-NN 0.8018 \n",
      " 19-NN 0.7923 \n",
      " 21-NN 0.7876 \n",
      " 23-NN 0.7839 \n",
      " 25-NN 0.7811 \n",
      " 27-NN 0.7716 \n",
      " 29-NN 0.7716 \n",
      " 31-NN 0.7726 \n",
      "ensemble 0.8085 \n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results (unsorted)\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1-NN 0.8029 \n",
      "  3-NN 0.8276 \n",
      "  5-NN 0.8199 \n",
      "  7-NN 0.8256 \n",
      "  9-NN 0.8226 \n",
      " 11-NN 0.8066 \n",
      " 13-NN 0.8095 \n",
      " 15-NN 0.8113 \n",
      " 17-NN 0.8018 \n",
      " 19-NN 0.7923 \n",
      " 21-NN 0.7876 \n",
      " 23-NN 0.7839 \n",
      " 25-NN 0.7811 \n",
      " 27-NN 0.7716 \n",
      " 29-NN 0.7716 \n",
      " 31-NN 0.7726 \n",
      "ensemble 0.8085 \n"
     ]
    }
   ],
   "source": [
    "# evaluate the models and store results (sorted)\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Australian data set contine 690 randuri de date, 42 de feature-uri, feature-ul pe care il vom clasifica este F15 care are 2 posibile clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Australian dataset\n",
      "  1-NN 0.6583 \n",
      "  3-NN 0.6801 \n",
      "  5-NN 0.6815 \n",
      "  7-NN 0.7047 \n",
      "  9-NN 0.6948 \n",
      " 11-NN 0.6991 \n",
      " 13-NN 0.6890 \n",
      " 15-NN 0.6875 \n",
      " 17-NN 0.6903 \n",
      " 19-NN 0.6847 \n",
      " 21-NN 0.6845 \n",
      " 23-NN 0.6903 \n",
      " 25-NN 0.7019 \n",
      "ensemble 0.6933 \n",
      "Best accuracy :  7-NN with accuracy 0.7047 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Australian dataset')\n",
    "input_file = \"australian.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F15')], data['F15']\n",
    "\n",
    "n=int(math.sqrt(690))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance data set contine 625 randuri de date, 4 feature-uri, feature-ul pe care il vom clasifica este F1 care are 3 posibile clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Balance dataset\n",
      "  1-NN 0.7792 \n",
      "  3-NN 0.7952 \n",
      "  5-NN 0.8160 \n",
      "  7-NN 0.8752 \n",
      "  9-NN 0.8896 \n",
      " 11-NN 0.8896 \n",
      " 13-NN 0.8832 \n",
      " 15-NN 0.8864 \n",
      " 17-NN 0.8864 \n",
      " 19-NN 0.8928 \n",
      " 21-NN 0.8992 \n",
      " 23-NN 0.8976 \n",
      " 25-NN 0.9024 \n",
      "ensemble 0.8976 \n",
      "Best accuracy : 25-NN with accuracy 0.9024 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Balance dataset')\n",
    "input_file = \"balance.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F1')], data['F1']\n",
    "\n",
    "n=int(math.sqrt(625))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banknote data set contine 1372 randuri de date, 5 feature-uri, feature-ul pe care il vom clasifica este F5 care are 2 posibile clase "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Banknote dataset\n",
      "  1-NN 0.9993 \n",
      "  3-NN 0.9993 \n",
      "  5-NN 1.0000 \n",
      "  7-NN 1.0000 \n",
      "  9-NN 1.0000 \n",
      " 11-NN 1.0000 \n",
      " 13-NN 1.0000 \n",
      " 15-NN 1.0000 \n",
      " 17-NN 0.9985 \n",
      " 19-NN 0.9949 \n",
      " 21-NN 0.9949 \n",
      " 23-NN 0.9927 \n",
      " 25-NN 0.9927 \n",
      " 27-NN 0.9927 \n",
      " 29-NN 0.9927 \n",
      " 31-NN 0.9927 \n",
      " 33-NN 0.9927 \n",
      " 35-NN 0.9927 \n",
      " 37-NN 0.9927 \n",
      "ensemble 0.9949 \n",
      "Best accuracy :  5-NN with accuracy 1.0000 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Banknote dataset')\n",
    "input_file = \"banknote.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F5')], data['F5']\n",
    "\n",
    "n=int(math.sqrt(1372))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haberman data set contine 306 randuri de date, 4 feature-uri, feature-ul pe care il vom clasifica este F4 care are 2 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Haberman dataset\n",
      "  1-NN 0.6503 \n",
      "  3-NN 0.6895 \n",
      "  5-NN 0.7092 \n",
      "  7-NN 0.7255 \n",
      "  9-NN 0.7451 \n",
      " 11-NN 0.7516 \n",
      " 13-NN 0.7582 \n",
      " 15-NN 0.7484 \n",
      " 17-NN 0.7451 \n",
      "ensemble 0.7451 \n",
      "Best accuracy : 13-NN with accuracy 0.7582 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Haberman dataset')\n",
    "input_file = \"haberman.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F4')], data['F4']\n",
    "\n",
    "n=int(math.sqrt(306))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart data set contine 271 randuri de date, 14 feature-uri, feature-ul pe care il vom clasifica este F14 care are 2 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Heart dataset\n",
      "  1-NN 0.6037 \n",
      "  3-NN 0.6519 \n",
      "  5-NN 0.6593 \n",
      "  7-NN 0.6667 \n",
      "  9-NN 0.6519 \n",
      " 11-NN 0.6593 \n",
      " 13-NN 0.6593 \n",
      " 15-NN 0.6593 \n",
      "ensemble 0.6630 \n",
      "Best accuracy :  7-NN with accuracy 0.6667 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Heart dataset')\n",
    "input_file = \"heart.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F14')], data['F14']\n",
    "\n",
    "n=int(math.sqrt(271))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionosphere data set contine 351 randuri de date, 35 feature-uri, feature-ul pe care il vom clasifica este F35 care are 2 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Ionosphere dataset\n",
      "  1-NN 0.8657 \n",
      "  3-NN 0.8457 \n",
      "  5-NN 0.8457 \n",
      "  7-NN 0.8288 \n",
      "  9-NN 0.8288 \n",
      " 11-NN 0.8345 \n",
      " 13-NN 0.8347 \n",
      " 15-NN 0.8316 \n",
      " 17-NN 0.8375 \n",
      "ensemble 0.8288 \n",
      "Best accuracy :  1-NN with accuracy 0.8657 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Ionosphere dataset')\n",
    "input_file = \"ionosphere.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F35')], data['F35']\n",
    "\n",
    "n=int(math.sqrt(351))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris data set contine 151 randuri de date, 5 feature-uri, feature-ul pe care il vom clasifica este F5 care are 3 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Iris dataset\n",
      "  1-NN 0.9600 \n",
      "  3-NN 0.9600 \n",
      "  5-NN 0.9667 \n",
      "  7-NN 0.9667 \n",
      "  9-NN 0.9667 \n",
      " 11-NN 0.9733 \n",
      "ensemble 0.9667 \n",
      "Best accuracy : 11-NN with accuracy 0.9733 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Iris dataset')\n",
    "input_file = \"iris.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F5')], data['F5']\n",
    "\n",
    "n=int(math.sqrt(151))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liver data set contine 345 randuri de date, 7 feature-uri, feature-ul pe care il vom clasifica este F7 care are 2 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Liver dataset\n",
      "  1-NN 0.6143 \n",
      "  3-NN 0.6422 \n",
      "  5-NN 0.6604 \n",
      "  7-NN 0.6925 \n",
      "  9-NN 0.7044 \n",
      " 11-NN 0.6875 \n",
      " 13-NN 0.6873 \n",
      " 15-NN 0.6932 \n",
      " 17-NN 0.6873 \n",
      "ensemble 0.6901 \n",
      "Best accuracy :  9-NN with accuracy 0.7044 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Liver dataset')\n",
    "input_file = \"liver.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F7')], data['F7']\n",
    "\n",
    "n=int(math.sqrt(345))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parkinson data set contine 1040 randuri de date, 27 feature-uri, feature-ul pe care il vom clasifica este F1 care are 2 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Parkinson dataset\n",
      "  1-NN 0.6062 \n",
      "  3-NN 0.5888 \n",
      "  5-NN 0.5111 \n",
      "  7-NN 0.4939 \n",
      "  9-NN 0.4405 \n",
      " 11-NN 0.3631 \n",
      "ensemble 0.4938 \n",
      "Best accuracy :  1-NN with accuracy 0.6062 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Parkinson dataset')\n",
    "input_file = \"parkinson.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F1')], data['F1']\n",
    "\n",
    "n=int(math.sqrt(168))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sonar data set contine 209 randuri de date, 61 feature-uri, feature-ul pe care il vom clasifica este F61 care are 2 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Sonar dataset\n",
      "  1-NN 0.8074 \n",
      "  3-NN 0.8075 \n",
      "  5-NN 0.7784 \n",
      "  7-NN 0.7204 \n",
      "  9-NN 0.6725 \n",
      " 11-NN 0.6725 \n",
      " 13-NN 0.6533 \n",
      "ensemble 0.7398 \n",
      "Best accuracy :  3-NN with accuracy 0.8075 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Sonar dataset')\n",
    "input_file = \"sonar.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F61')], data['F61']\n",
    "\n",
    "n=int(math.sqrt(209))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine data set contine 179 randuri de date, 13 feature-uri, feature-ul pe care il vom clasifica este F1 care are 3 posibile clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate Wine dataset\n",
      "  1-NN 0.7525 \n",
      "  3-NN 0.7197 \n",
      "  5-NN 0.7138 \n",
      "  7-NN 0.7190 \n",
      "  9-NN 0.7082 \n",
      " 11-NN 0.7136 \n",
      " 13-NN 0.6910 \n",
      "ensemble 0.7473 \n",
      "Best accuracy :  1-NN with accuracy 0.7525 \n"
     ]
    }
   ],
   "source": [
    "print('Evaluate Wine dataset')\n",
    "input_file = \"wine.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F1')], data['F1']\n",
    "\n",
    "n=int(math.sqrt(179))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG data set contine 14980 randuri de date, 15 feature-uri, feature-ul pe care il vom clasifica este F15 care are 2 posibile clase (loading time > 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Evaluate EEG dataset')\n",
    "input_file = \"EEG.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F15')], data['F15']\n",
    "\n",
    "n=int(math.sqrt(14980))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Letter recognition data set contine 20000 randuri de date, 16 feature-uri, feature-ul pe care il vom clasifica este F1 care are 26 posibile clase (loading time > 5 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluate Letter-Recognition dataset')\n",
    "input_file = \"letter-recognition.csv\"\n",
    "\n",
    "data = pd.read_csv(input_file, header = 0)\n",
    "\n",
    "X, y = data[data.columns.drop('F1')], data['F1']\n",
    "\n",
    "n=int(math.sqrt(20000))\n",
    "\n",
    "\n",
    "if(n % 2 == 0):\n",
    "\tn=n-1\n",
    "\n",
    "models = get_models(n)\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "bestName=\"1NN\"; bestAccuracy=0;\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tzipped= zip(names, results)\n",
    "names, results = zip(*sorted(zipped))\n",
    "for x in range (len(names)): \t\n",
    "\tprint('%s %.4f ' % (names[x], mean(results[x])))\n",
    "\tif(mean(results[x])> bestAccuracy):\n",
    "\t\tbestName= names[x]; \n",
    "\t\tbestAccuracy= mean(results[x]);\n",
    "print('Best accuracy :%s with accuracy %.4f '% (bestName, bestAccuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluzii: \n",
    "# Toate seturile de date evaluate anterior au fost evaluate si in articolul ales de mine, restul seturilor de date care sunt prezentate in articol si nu sunt regasite mai sus nu mai sunt disponibile pe site-ul din bibliografie. \n",
    "\n",
    "# In urma experimentelor am remarcat ca desi clasificatorul asamblat descris in articol nu depaseste performanta celui mai bun clasificator KNN din ansamblul sau performanta ansamblului este foarte apropiata de cea mai buna performanta, scutundu-ne de cautarea parametrului k care ar avea cea mai buna performanta. \n",
    "\n",
    "# De asemenea am remarcat ca performantele optinute ruland codul python din terminal(folosind versiunea 2.7.3) si cea optinuta din acest notebook(care foloseste versiunea 3) sunt diferite"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
